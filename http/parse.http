#@host = https://europe-west1-default-386621.cloudfunctions.net/mardown-to-html
#@host = https://cr-apache-m2h-4yexhpt4xq-ew.a.run.app/
#@host = https://cr-frankenphp-m2h-4yexhpt4xq-ew.a.run.app/
#@host = https://cr-binary-m2h-4yexhpt4xq-ew.a.run.app/
#@host = https://europe-west1-default-386621.cloudfunctions.net/markdown-to-html-go
@host = https://cr-nginx-fpm-m2h-4yexhpt4xq-ew.a.run.app
POST {{host}}/
Content-Type: application/json

{
  "data": "# Cloud Function\n\nPremier test avec une Cloud Function en PHP.\n\n```php\nFunctionsFramework::http('index', 'index');\n\nfunction index(ServerRequestInterface $request): ResponseInterface\n{\n    if ('POST' !== $request->getMethod() || empty($body = $request->getBody()->getContents())) {\n        return new Response(status: 400);\n    }\n\n    $json = json_decode($body, true);\n    if (json_last_error() !== JSON_ERROR_NONE) {\n        throw new RuntimeException(sprintf('Could not parse body: %s', json_last_error_msg()));\n    }\n\n    $html = (new Parsedown())->parse($json['data'] ?? '');\n\n    return new Response(status: 200, body: json_encode(['result' => $html]));\n}\n```\n\nLa CF est simple et l'essentiel de la charge est portée par la\ndépendance [Parsedown](https://github.com/erusev/parsedown), ce qui n'est pas un problème pour la comparaison puisque\nles autres utilise la même dépendance.\n\nDéploiement de la fonction via gcloud\n\n```shell\ngcloud functions deploy mardown-to-html \\n    --gen2 \\n    --runtime=php82 \\n    --region=europe-west1 \\n    --source=./cloud-function/ \\n    --entry-point=index \\n    --trigger-http \\n    --allow-unauthenticated\n```\n\nPour le test, j'utilise [hey](https://github.com/rakyll/hey) :\n\n> On a 100 processus en continu pendant 1 minute qui vont effectuer la même requête.\n\n<details>\n<summary>Résultat du test : <strong>1374 req/sec</strong></summary>\n\n```shell\nSummary:\n  Total: 60.0715 secs\n  Slowest: 1.5860 secs\n  Fastest: 0.0342 secs\n  Average: 0.0727 secs\n  Requests/sec: 1374.1454\n  \n\nResponse time histogram:\n  0.034 [1] |\n  0.189 [81570] |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  0.345 [753] |\n  0.500 [52] |\n  0.655 [71] |\n  0.810 [7] |\n  0.965 [81] |\n  1.120 [0] |\n  1.276 [0] |\n  1.431 [0] |\n  1.586 [12] |\n\n\nLatency distribution:\n  10% in 0.0507 secs\n  25% in 0.0601 secs\n  50% in 0.0674 secs\n  75% in 0.0756 secs\n  90% in 0.0880 secs\n  95% in 0.1054 secs\n  99% in 0.1990 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup: 0.0000 secs, 0.0342 secs, 1.5860 secs\n  DNS-lookup: 0.0000 secs, 0.0000 secs, 0.0008 secs\n  req write: 0.0000 secs, 0.0000 secs, 0.0016 secs\n  resp wait: 0.0713 secs, 0.0336 secs, 1.2923 secs\n  resp read: 0.0010 secs, 0.0000 secs, 0.4074 secs\n\nStatus code distribution:\n  [200] 82547 responses\n``` \n\n</details>\n # Cloud Function\n\nPremier test avec une Cloud Function en PHP.\n\n```php\nFunctionsFramework::http('index', 'index');\n\nfunction index(ServerRequestInterface $request): ResponseInterface\n{\n    if ('POST' !== $request->getMethod() || empty($body = $request->getBody()->getContents())) {\n        return new Response(status: 400);\n    }\n\n    $json = json_decode($body, true);\n    if (json_last_error() !== JSON_ERROR_NONE) {\n        throw new RuntimeException(sprintf('Could not parse body: %s', json_last_error_msg()));\n    }\n\n    $html = (new Parsedown())->parse($json['data'] ?? '');\n\n    return new Response(status: 200, body: json_encode(['result' => $html]));\n}\n```\n\nLa CF est simple et l'essentiel de la charge est portée par la\ndépendance [Parsedown](https://github.com/erusev/parsedown), ce qui n'est pas un problème pour la comparaison puisque\nles autres utilise la même dépendance.\n\nDéploiement de la fonction via gcloud\n\n```shell\ngcloud functions deploy mardown-to-html \\n    --gen2 \\n    --runtime=php82 \\n    --region=europe-west1 \\n    --source=./cloud-function/ \\n    --entry-point=index \\n    --trigger-http \\n    --allow-unauthenticated\n```\n\nPour le test, j'utilise [hey](https://github.com/rakyll/hey) :\n\n> On a 100 processus en continu pendant 1 minute qui vont effectuer la même requête.\n\n<details>\n<summary>Résultat du test : <strong>1374 req/sec</strong></summary>\n\n```shell\nSummary:\n  Total: 60.0715 secs\n  Slowest: 1.5860 secs\n  Fastest: 0.0342 secs\n  Average: 0.0727 secs\n  Requests/sec: 1374.1454\n  \n\nResponse time histogram:\n  0.034 [1] |\n  0.189 [81570] |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  0.345 [753] |\n  0.500 [52] |\n  0.655 [71] |\n  0.810 [7] |\n  0.965 [81] |\n  1.120 [0] |\n  1.276 [0] |\n  1.431 [0] |\n  1.586 [12] |\n\n\nLatency distribution:\n  10% in 0.0507 secs\n  25% in 0.0601 secs\n  50% in 0.0674 secs\n  75% in 0.0756 secs\n  90% in 0.0880 secs\n  95% in 0.1054 secs\n  99% in 0.1990 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup: 0.0000 secs, 0.0342 secs, 1.5860 secs\n  DNS-lookup: 0.0000 secs, 0.0000 secs, 0.0008 secs\n  req write: 0.0000 secs, 0.0000 secs, 0.0016 secs\n  resp wait: 0.0713 secs, 0.0336 secs, 1.2923 secs\n  resp read: 0.0010 secs, 0.0000 secs, 0.4074 secs\n\nStatus code distribution:\n  [200] 82547 responses\n``` \n\n</details>\n # Cloud Function\n\nPremier test avec une Cloud Function en PHP.\n\n```php\nFunctionsFramework::http('index', 'index');\n\nfunction index(ServerRequestInterface $request): ResponseInterface\n{\n    if ('POST' !== $request->getMethod() || empty($body = $request->getBody()->getContents())) {\n        return new Response(status: 400);\n    }\n\n    $json = json_decode($body, true);\n    if (json_last_error() !== JSON_ERROR_NONE) {\n        throw new RuntimeException(sprintf('Could not parse body: %s', json_last_error_msg()));\n    }\n\n    $html = (new Parsedown())->parse($json['data'] ?? '');\n\n    return new Response(status: 200, body: json_encode(['result' => $html]));\n}\n```\n\nLa CF est simple et l'essentiel de la charge est portée par la\ndépendance [Parsedown](https://github.com/erusev/parsedown), ce qui n'est pas un problème pour la comparaison puisque\nles autres utilise la même dépendance.\n\nDéploiement de la fonction via gcloud\n\n```shell\ngcloud functions deploy mardown-to-html \\n    --gen2 \\n    --runtime=php82 \\n    --region=europe-west1 \\n    --source=./cloud-function/ \\n    --entry-point=index \\n    --trigger-http \\n    --allow-unauthenticated\n```\n\nPour le test, j'utilise [hey](https://github.com/rakyll/hey) :\n\n> On a 100 processus en continu pendant 1 minute qui vont effectuer la même requête.\n\n<details>\n<summary>Résultat du test : <strong>1374 req/sec</strong></summary>\n\n```shell\nSummary:\n  Total: 60.0715 secs\n  Slowest: 1.5860 secs\n  Fastest: 0.0342 secs\n  Average: 0.0727 secs\n  Requests/sec: 1374.1454\n  \n\nResponse time histogram:\n  0.034 [1] |\n  0.189 [81570] |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  0.345 [753] |\n  0.500 [52] |\n  0.655 [71] |\n  0.810 [7] |\n  0.965 [81] |\n  1.120 [0] |\n  1.276 [0] |\n  1.431 [0] |\n  1.586 [12] |\n\n\nLatency distribution:\n  10% in 0.0507 secs\n  25% in 0.0601 secs\n  50% in 0.0674 secs\n  75% in 0.0756 secs\n  90% in 0.0880 secs\n  95% in 0.1054 secs\n  99% in 0.1990 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup: 0.0000 secs, 0.0342 secs, 1.5860 secs\n  DNS-lookup: 0.0000 secs, 0.0000 secs, 0.0008 secs\n  req write: 0.0000 secs, 0.0000 secs, 0.0016 secs\n  resp wait: 0.0713 secs, 0.0336 secs, 1.2923 secs\n  resp read: 0.0010 secs, 0.0000 secs, 0.4074 secs\n\nStatus code distribution:\n  [200] 82547 responses\n``` \n\n</details>\n# Cloud Function\n\nPremier test avec une Cloud Function en PHP.\n\n```php\nFunctionsFramework::http('index', 'index');\n\nfunction index(ServerRequestInterface $request): ResponseInterface\n{\n    if ('POST' !== $request->getMethod() || empty($body = $request->getBody()->getContents())) {\n        return new Response(status: 400);\n    }\n\n    $json = json_decode($body, true);\n    if (json_last_error() !== JSON_ERROR_NONE) {\n        throw new RuntimeException(sprintf('Could not parse body: %s', json_last_error_msg()));\n    }\n\n    $html = (new Parsedown())->parse($json['data'] ?? '');\n\n    return new Response(status: 200, body: json_encode(['result' => $html]));\n}\n```\n\nLa CF est simple et l'essentiel de la charge est portée par la\ndépendance [Parsedown](https://github.com/erusev/parsedown), ce qui n'est pas un problème pour la comparaison puisque\nles autres utilise la même dépendance.\n\nDéploiement de la fonction via gcloud\n\n```shell\ngcloud functions deploy mardown-to-html \\n    --gen2 \\n    --runtime=php82 \\n    --region=europe-west1 \\n    --source=./cloud-function/ \\n    --entry-point=index \\n    --trigger-http \\n    --allow-unauthenticated\n```\n\nPour le test, j'utilise [hey](https://github.com/rakyll/hey) :\n\n> On a 100 processus en continu pendant 1 minute qui vont effectuer la même requête.\n\n<details>\n<summary>Résultat du test : <strong>1374 req/sec</strong></summary>\n\n```shell\nSummary:\n  Total: 60.0715 secs\n  Slowest: 1.5860 secs\n  Fastest: 0.0342 secs\n  Average: 0.0727 secs\n  Requests/sec: 1374.1454\n  \n\nResponse time histogram:\n  0.034 [1] |\n  0.189 [81570] |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  0.345 [753] |\n  0.500 [52] |\n  0.655 [71] |\n  0.810 [7] |\n  0.965 [81] |\n  1.120 [0] |\n  1.276 [0] |\n  1.431 [0] |\n  1.586 [12] |\n\n\nLatency distribution:\n  10% in 0.0507 secs\n  25% in 0.0601 secs\n  50% in 0.0674 secs\n  75% in 0.0756 secs\n  90% in 0.0880 secs\n  95% in 0.1054 secs\n  99% in 0.1990 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup: 0.0000 secs, 0.0342 secs, 1.5860 secs\n  DNS-lookup: 0.0000 secs, 0.0000 secs, 0.0008 secs\n  req write: 0.0000 secs, 0.0000 secs, 0.0016 secs\n  resp wait: 0.0713 secs, 0.0336 secs, 1.2923 secs\n  resp read: 0.0010 secs, 0.0000 secs, 0.4074 secs\n\nStatus code distribution:\n  [200] 82547 responses\n``` \n\n</details>\n"
}
